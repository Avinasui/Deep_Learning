{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "gQLpOZfwZ7Gs"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "MO7_Ag7EaCoZ",
        "outputId": "106cc5fe-c669-40fa-b030-57d3b3af4ef8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"C:\\\\Users\\\\varun\\\\Downloads\\\\data.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_UHMvTEaT_L",
        "outputId": "46cbf253-c823-47dc-e9c6-1a25233f25e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569, 33)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JssWvTd9aXTU",
        "outputId": "0a1a1696-4c5c-4b95-f030-1812ec70dee2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                           0\n",
              "diagnosis                    0\n",
              "radius_mean                  0\n",
              "texture_mean                 0\n",
              "perimeter_mean               0\n",
              "area_mean                    0\n",
              "smoothness_mean              0\n",
              "compactness_mean             0\n",
              "concavity_mean               0\n",
              "concave points_mean          0\n",
              "symmetry_mean                0\n",
              "fractal_dimension_mean       0\n",
              "radius_se                    0\n",
              "texture_se                   0\n",
              "perimeter_se                 0\n",
              "area_se                      0\n",
              "smoothness_se                0\n",
              "compactness_se               0\n",
              "concavity_se                 0\n",
              "concave points_se            0\n",
              "symmetry_se                  0\n",
              "fractal_dimension_se         0\n",
              "radius_worst                 0\n",
              "texture_worst                0\n",
              "perimeter_worst              0\n",
              "area_worst                   0\n",
              "smoothness_worst             0\n",
              "compactness_worst            0\n",
              "concavity_worst              0\n",
              "concave points_worst         0\n",
              "symmetry_worst               0\n",
              "fractal_dimension_worst      0\n",
              "Unnamed: 32                569\n",
              "dtype: int64"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdlwRblEab4t",
        "outputId": "2baff41b-b0c7-4528-9e37-6d52d7509bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "bEDewz-Tbm7U"
      },
      "outputs": [],
      "source": [
        "df.drop(['id','Unnamed: 32'],axis = 1,inplace =True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "U0zflviebm-r",
        "outputId": "88513195-c3a3-4595-e142-5ea9e6cff6e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0         M        17.99         10.38          122.80     1001.0   \n",
              "1         M        20.57         17.77          132.90     1326.0   \n",
              "2         M        19.69         21.25          130.00     1203.0   \n",
              "3         M        11.42         20.38           77.58      386.1   \n",
              "4         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0         0.2419  ...         25.38          17.33           184.60   \n",
              "1         0.1812  ...         24.99          23.41           158.80   \n",
              "2         0.2069  ...         23.57          25.53           152.50   \n",
              "3         0.2597  ...         14.91          26.50            98.87   \n",
              "4         0.1809  ...         22.54          16.67           152.20   \n",
              "\n",
              "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw4bqhzSafar",
        "outputId": "c24b817c-5ed2-4e51-adec-4f1bbe99a36e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "diagnosis\n",
              "B    357\n",
              "M    212\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.diagnosis.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "KHbkby2Namkf"
      },
      "outputs": [],
      "source": [
        "X= df.drop(['diagnosis'],axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTm6_v9McIxa",
        "outputId": "1f41d668-1811-4e91-cffe-f3467bdd0300"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    M\n",
              "1    M\n",
              "2    M\n",
              "3    M\n",
              "4    M\n",
              "Name: diagnosis, dtype: object"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df.diagnosis\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "LjhAns_wcKhQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le =LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "qYofqvrzcbY0"
      },
      "outputs": [],
      "source": [
        "y =le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_FwwANaci9m",
        "outputId": "3ecb9efb-fb14-48c7-a4fb-4f6706d32aca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "4CXatt3MckW3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX6_P3lQcyzU",
        "outputId": "51ff3292-8839-4665-d929-8439ab5add21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((455, 30), (114, 30))"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape,x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "JzwNLhevcy1n"
      },
      "outputs": [],
      "source": [
        "# Creating ANN structure\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "vTMaxhcKcy30"
      },
      "outputs": [],
      "source": [
        "\n",
        "classification = Sequential()\n",
        "classification.add(Dense(30,activation='relu'))\n",
        "classification.add(Dense(128,activation='relu'))\n",
        "classification.add(Dense(64,activation='relu'))\n",
        "classification.add(Dense(32,activation='relu'))\n",
        "classification.add(Dense(1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "zKaYn5Jzcy7a"
      },
      "outputs": [],
      "source": [
        "# Compiling ANN model\n",
        "\n",
        "classification.compile(optimizer='adam',loss ='binary_crossentropy',metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JdnNVvLdpSG",
        "outputId": "a6ee7f15-4bf1-4426-89d6-bbd6d58f2709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 2s 2ms/step - loss: 1.7124 - accuracy: 0.6857\n",
            "Epoch 2/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.8154\n",
            "Epoch 3/300\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8835\n",
            "Epoch 4/300\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8945\n",
            "Epoch 5/300\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.9011\n",
            "Epoch 6/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8989\n",
            "Epoch 7/300\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8791\n",
            "Epoch 8/300\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8703\n",
            "Epoch 9/300\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8527\n",
            "Epoch 10/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.8637\n",
            "Epoch 11/300\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8813\n",
            "Epoch 12/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8967\n",
            "Epoch 13/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9143\n",
            "Epoch 14/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9143\n",
            "Epoch 15/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9099\n",
            "Epoch 16/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.9143\n",
            "Epoch 17/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.8879\n",
            "Epoch 18/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9209\n",
            "Epoch 19/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9231\n",
            "Epoch 20/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9121\n",
            "Epoch 21/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8901\n",
            "Epoch 22/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9209\n",
            "Epoch 23/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9253\n",
            "Epoch 24/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.9165\n",
            "Epoch 25/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9319\n",
            "Epoch 26/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.9187\n",
            "Epoch 27/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1822 - accuracy: 0.9297\n",
            "Epoch 28/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9297\n",
            "Epoch 29/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9231\n",
            "Epoch 30/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9253\n",
            "Epoch 31/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9253\n",
            "Epoch 32/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9297\n",
            "Epoch 33/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9209\n",
            "Epoch 34/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.9055\n",
            "Epoch 35/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1994 - accuracy: 0.9187\n",
            "Epoch 36/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2442 - accuracy: 0.9033\n",
            "Epoch 37/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8945\n",
            "Epoch 38/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1965 - accuracy: 0.9209\n",
            "Epoch 39/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.9319\n",
            "Epoch 40/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1814 - accuracy: 0.9297\n",
            "Epoch 41/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9385\n",
            "Epoch 42/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9253\n",
            "Epoch 43/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9341\n",
            "Epoch 44/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9319\n",
            "Epoch 45/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1685 - accuracy: 0.9385\n",
            "Epoch 46/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9385\n",
            "Epoch 47/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.9121\n",
            "Epoch 48/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2236 - accuracy: 0.9077\n",
            "Epoch 49/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9275\n",
            "Epoch 50/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.9319\n",
            "Epoch 51/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9341\n",
            "Epoch 52/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9297\n",
            "Epoch 53/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.9011\n",
            "Epoch 54/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1770 - accuracy: 0.9341\n",
            "Epoch 55/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1902 - accuracy: 0.9253\n",
            "Epoch 56/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2179 - accuracy: 0.8989\n",
            "Epoch 57/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9451\n",
            "Epoch 58/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.9429\n",
            "Epoch 59/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9341\n",
            "Epoch 60/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9341\n",
            "Epoch 61/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9055\n",
            "Epoch 62/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9341\n",
            "Epoch 63/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9341\n",
            "Epoch 64/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9385\n",
            "Epoch 65/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9385\n",
            "Epoch 66/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9319\n",
            "Epoch 67/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9363\n",
            "Epoch 68/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9429\n",
            "Epoch 69/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9319\n",
            "Epoch 70/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.9077\n",
            "Epoch 71/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9385\n",
            "Epoch 72/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9099\n",
            "Epoch 73/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9231\n",
            "Epoch 74/300\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.9319\n",
            "Epoch 75/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9385\n",
            "Epoch 76/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.9385\n",
            "Epoch 77/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9275\n",
            "Epoch 78/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9319\n",
            "Epoch 79/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.9363\n",
            "Epoch 80/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9429\n",
            "Epoch 81/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1638 - accuracy: 0.9407\n",
            "Epoch 82/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9473\n",
            "Epoch 83/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1626 - accuracy: 0.9407\n",
            "Epoch 84/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.9429\n",
            "Epoch 85/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9341\n",
            "Epoch 86/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9385\n",
            "Epoch 87/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1390 - accuracy: 0.9385\n",
            "Epoch 88/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.9429\n",
            "Epoch 89/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9407\n",
            "Epoch 90/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1600 - accuracy: 0.9297\n",
            "Epoch 91/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9407\n",
            "Epoch 92/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9363\n",
            "Epoch 93/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9341\n",
            "Epoch 94/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1262 - accuracy: 0.9407\n",
            "Epoch 95/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9385\n",
            "Epoch 96/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9385\n",
            "Epoch 97/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9385\n",
            "Epoch 98/300\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1313 - accuracy: 0.9451\n",
            "Epoch 99/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1376 - accuracy: 0.9341\n",
            "Epoch 100/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1296 - accuracy: 0.9385\n",
            "Epoch 101/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1387 - accuracy: 0.9473\n",
            "Epoch 102/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9363\n",
            "Epoch 103/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1424 - accuracy: 0.9275\n",
            "Epoch 104/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1288 - accuracy: 0.9516\n",
            "Epoch 105/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9473\n",
            "Epoch 106/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1411 - accuracy: 0.9363\n",
            "Epoch 107/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1469 - accuracy: 0.9363\n",
            "Epoch 108/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9451\n",
            "Epoch 109/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2332 - accuracy: 0.9033\n",
            "Epoch 110/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.9165\n",
            "Epoch 111/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9165\n",
            "Epoch 112/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9275\n",
            "Epoch 113/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.9121\n",
            "Epoch 114/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1622 - accuracy: 0.9341\n",
            "Epoch 115/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9429\n",
            "Epoch 116/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9473\n",
            "Epoch 117/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2407 - accuracy: 0.9275\n",
            "Epoch 118/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9407\n",
            "Epoch 119/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9516\n",
            "Epoch 120/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9407\n",
            "Epoch 121/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9473\n",
            "Epoch 122/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1624 - accuracy: 0.9363\n",
            "Epoch 123/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1231 - accuracy: 0.9516\n",
            "Epoch 124/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9495\n",
            "Epoch 125/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9560\n",
            "Epoch 126/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.9473\n",
            "Epoch 127/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1404 - accuracy: 0.9451\n",
            "Epoch 128/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9538\n",
            "Epoch 129/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1401 - accuracy: 0.9451\n",
            "Epoch 130/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9429\n",
            "Epoch 131/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9516\n",
            "Epoch 132/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9385\n",
            "Epoch 133/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.9275\n",
            "Epoch 134/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9582\n",
            "Epoch 135/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9495\n",
            "Epoch 136/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9538\n",
            "Epoch 137/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9560\n",
            "Epoch 138/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9495\n",
            "Epoch 139/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1645 - accuracy: 0.9385\n",
            "Epoch 140/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9429\n",
            "Epoch 141/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.9516\n",
            "Epoch 142/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9429\n",
            "Epoch 143/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9451\n",
            "Epoch 144/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9560\n",
            "Epoch 145/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9473\n",
            "Epoch 146/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9451\n",
            "Epoch 147/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.9516\n",
            "Epoch 148/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9582\n",
            "Epoch 149/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9495\n",
            "Epoch 150/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1252 - accuracy: 0.9451\n",
            "Epoch 151/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9495\n",
            "Epoch 152/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 0.9582\n",
            "Epoch 153/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1498 - accuracy: 0.9429\n",
            "Epoch 154/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9407\n",
            "Epoch 155/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9560\n",
            "Epoch 156/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9385\n",
            "Epoch 157/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9582\n",
            "Epoch 158/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9275\n",
            "Epoch 159/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9538\n",
            "Epoch 160/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9407\n",
            "Epoch 161/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.9341\n",
            "Epoch 162/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9407\n",
            "Epoch 163/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1152 - accuracy: 0.9516\n",
            "Epoch 164/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1380 - accuracy: 0.9385\n",
            "Epoch 165/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9451\n",
            "Epoch 166/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.9516\n",
            "Epoch 167/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9319\n",
            "Epoch 168/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9429\n",
            "Epoch 169/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9385\n",
            "Epoch 170/300\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1319 - accuracy: 0.9451\n",
            "Epoch 171/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9451\n",
            "Epoch 172/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1416 - accuracy: 0.9451\n",
            "Epoch 173/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9473\n",
            "Epoch 174/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1184 - accuracy: 0.9538\n",
            "Epoch 175/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.9516\n",
            "Epoch 176/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9538\n",
            "Epoch 177/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9538\n",
            "Epoch 178/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1463 - accuracy: 0.9341\n",
            "Epoch 179/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9516\n",
            "Epoch 180/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.9516\n",
            "Epoch 181/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9495\n",
            "Epoch 182/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9582\n",
            "Epoch 183/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1437 - accuracy: 0.9385\n",
            "Epoch 184/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1128 - accuracy: 0.9473\n",
            "Epoch 185/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1246 - accuracy: 0.9451\n",
            "Epoch 186/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9538\n",
            "Epoch 187/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0984 - accuracy: 0.9582\n",
            "Epoch 188/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9363\n",
            "Epoch 189/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9473\n",
            "Epoch 190/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1161 - accuracy: 0.9429\n",
            "Epoch 191/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.9516\n",
            "Epoch 192/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.9560\n",
            "Epoch 193/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9692\n",
            "Epoch 194/300\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.9516\n",
            "Epoch 195/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0975 - accuracy: 0.9648\n",
            "Epoch 196/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1106 - accuracy: 0.9495\n",
            "Epoch 197/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1104 - accuracy: 0.9451\n",
            "Epoch 198/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9538\n",
            "Epoch 199/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 0.9560\n",
            "Epoch 200/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9604\n",
            "Epoch 201/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9407\n",
            "Epoch 202/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9516\n",
            "Epoch 203/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9648\n",
            "Epoch 204/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9407\n",
            "Epoch 205/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9407\n",
            "Epoch 206/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.9495\n",
            "Epoch 207/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9495\n",
            "Epoch 208/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9495\n",
            "Epoch 209/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9604\n",
            "Epoch 210/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9604\n",
            "Epoch 211/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0896 - accuracy: 0.9604\n",
            "Epoch 212/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9670\n",
            "Epoch 213/300\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1733 - accuracy: 0.9319\n",
            "Epoch 214/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1106 - accuracy: 0.9582\n",
            "Epoch 215/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9341\n",
            "Epoch 216/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9648\n",
            "Epoch 217/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.9604\n",
            "Epoch 218/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9495\n",
            "Epoch 219/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1252 - accuracy: 0.9473\n",
            "Epoch 220/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9516\n",
            "Epoch 221/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9538\n",
            "Epoch 222/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1005 - accuracy: 0.9604\n",
            "Epoch 223/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9560\n",
            "Epoch 224/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.9582\n",
            "Epoch 225/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1204 - accuracy: 0.9495\n",
            "Epoch 226/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9495\n",
            "Epoch 227/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9648\n",
            "Epoch 228/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0817 - accuracy: 0.9670\n",
            "Epoch 229/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9648\n",
            "Epoch 230/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9538\n",
            "Epoch 231/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0927 - accuracy: 0.9582\n",
            "Epoch 232/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.9473\n",
            "Epoch 233/300\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9538\n",
            "Epoch 234/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9604\n",
            "Epoch 235/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0974 - accuracy: 0.9516\n",
            "Epoch 236/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0792 - accuracy: 0.9670\n",
            "Epoch 237/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9495\n",
            "Epoch 238/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.9604\n",
            "Epoch 239/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1521 - accuracy: 0.9692\n",
            "Epoch 240/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1467 - accuracy: 0.9319\n",
            "Epoch 241/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0972 - accuracy: 0.9670\n",
            "Epoch 242/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.9473\n",
            "Epoch 243/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1204 - accuracy: 0.9495\n",
            "Epoch 244/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9692\n",
            "Epoch 245/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9451\n",
            "Epoch 246/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0972 - accuracy: 0.9582\n",
            "Epoch 247/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9692\n",
            "Epoch 248/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9714\n",
            "Epoch 249/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9626\n",
            "Epoch 250/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9714\n",
            "Epoch 251/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9648\n",
            "Epoch 252/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9648\n",
            "Epoch 253/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9626\n",
            "Epoch 254/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9516\n",
            "Epoch 255/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9538\n",
            "Epoch 256/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9560\n",
            "Epoch 257/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9495\n",
            "Epoch 258/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0861 - accuracy: 0.9626\n",
            "Epoch 259/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9538\n",
            "Epoch 260/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9692\n",
            "Epoch 261/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0740 - accuracy: 0.9736\n",
            "Epoch 262/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0884 - accuracy: 0.9582\n",
            "Epoch 263/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1015 - accuracy: 0.9582\n",
            "Epoch 264/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9648\n",
            "Epoch 265/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9714\n",
            "Epoch 266/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9626\n",
            "Epoch 267/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9538\n",
            "Epoch 268/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1080 - accuracy: 0.9538\n",
            "Epoch 269/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9648\n",
            "Epoch 270/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9692\n",
            "Epoch 271/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9736\n",
            "Epoch 272/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9473\n",
            "Epoch 273/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9648\n",
            "Epoch 274/300\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9604\n",
            "Epoch 275/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9604\n",
            "Epoch 276/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9714\n",
            "Epoch 277/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.9516\n",
            "Epoch 278/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9538\n",
            "Epoch 279/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9714\n",
            "Epoch 280/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9670\n",
            "Epoch 281/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9648\n",
            "Epoch 282/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9670\n",
            "Epoch 283/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0892 - accuracy: 0.9582\n",
            "Epoch 284/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9626\n",
            "Epoch 285/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9560\n",
            "Epoch 286/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9670\n",
            "Epoch 287/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0981 - accuracy: 0.9560\n",
            "Epoch 288/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9604\n",
            "Epoch 289/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9516\n",
            "Epoch 290/300\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.0974 - accuracy: 0.9604\n",
            "Epoch 291/300\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9714\n",
            "Epoch 292/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0938 - accuracy: 0.9516\n",
            "Epoch 293/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1049 - accuracy: 0.9582\n",
            "Epoch 294/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9451\n",
            "Epoch 295/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9626\n",
            "Epoch 296/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9692\n",
            "Epoch 297/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.9670\n",
            "Epoch 298/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1104 - accuracy: 0.9451\n",
            "Epoch 299/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9670\n",
            "Epoch 300/300\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0782 - accuracy: 0.9604\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x296b4579a10>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# training the model\n",
        "classification.fit(x_train,y_train,batch_size=10,epochs =300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk_9kfx_dpT2",
        "outputId": "ed53b73e-18be-402b-818f-1bb414c3d521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "# testing the model\n",
        "\n",
        "y_pred = classification.predict(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G5w82hzeq8j",
        "outputId": "0f65887a-7603-4c6b-ab57-bfd9d99dfcd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[9.9292594e-01],\n",
              "       [1.4478881e-02],\n",
              "       [2.7062513e-06],\n",
              "       [9.6303681e-03],\n",
              "       [7.8481964e-05],\n",
              "       [1.4203133e-08],\n",
              "       [7.7537470e-07],\n",
              "       [8.9890744e-09],\n",
              "       [2.7658579e-08],\n",
              "       [2.2037908e-10],\n",
              "       [6.3058739e-03],\n",
              "       [1.1309739e-02],\n",
              "       [2.7126975e-12],\n",
              "       [9.3092573e-01],\n",
              "       [1.5577385e-03],\n",
              "       [9.4697165e-01],\n",
              "       [2.8690665e-09],\n",
              "       [1.0000000e+00],\n",
              "       [9.9983573e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [5.2163810e-01],\n",
              "       [1.1235598e-09],\n",
              "       [5.0432420e-05],\n",
              "       [9.9975389e-01],\n",
              "       [7.0309750e-04],\n",
              "       [6.5385115e-09],\n",
              "       [2.0728604e-01],\n",
              "       [1.2052060e-07],\n",
              "       [1.0000000e+00],\n",
              "       [2.9230225e-08],\n",
              "       [9.9999994e-01],\n",
              "       [2.2460733e-02],\n",
              "       [9.9592090e-01],\n",
              "       [1.7877467e-14],\n",
              "       [9.9999636e-01],\n",
              "       [2.5495223e-03],\n",
              "       [9.9996144e-01],\n",
              "       [6.2240317e-05],\n",
              "       [9.9633276e-01],\n",
              "       [6.7067635e-01],\n",
              "       [1.2749646e-06],\n",
              "       [9.9190956e-01],\n",
              "       [1.4768639e-12],\n",
              "       [5.8082563e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.0438884e-13],\n",
              "       [1.9810409e-03],\n",
              "       [9.0486884e-07],\n",
              "       [9.9992353e-01],\n",
              "       [9.9457848e-01],\n",
              "       [3.5546795e-02],\n",
              "       [9.9999595e-01],\n",
              "       [2.6652358e-09],\n",
              "       [1.4341281e-03],\n",
              "       [1.2730616e-11],\n",
              "       [2.4421673e-10],\n",
              "       [1.1235816e-02],\n",
              "       [1.1875142e-03],\n",
              "       [1.0000000e+00],\n",
              "       [8.9530241e-01],\n",
              "       [9.8802489e-01],\n",
              "       [2.5850289e-07],\n",
              "       [2.4853065e-05],\n",
              "       [9.9999416e-01],\n",
              "       [4.5492208e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999869e-01],\n",
              "       [5.1132154e-11],\n",
              "       [1.1858533e-01],\n",
              "       [9.9999923e-01],\n",
              "       [8.6957916e-09],\n",
              "       [1.9382381e-01],\n",
              "       [9.9997848e-01],\n",
              "       [3.3757396e-03],\n",
              "       [4.7339125e-12],\n",
              "       [4.3579214e-04],\n",
              "       [4.6042701e-06],\n",
              "       [9.8891715e-06],\n",
              "       [9.8360831e-01],\n",
              "       [9.9999964e-01],\n",
              "       [9.9999934e-01],\n",
              "       [1.6431263e-04],\n",
              "       [7.2647893e-01],\n",
              "       [1.9645001e-11],\n",
              "       [2.9495957e-09],\n",
              "       [1.1188917e-12],\n",
              "       [9.9999738e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.9411000e-13],\n",
              "       [5.4382038e-01],\n",
              "       [2.5092289e-01],\n",
              "       [9.9978822e-01],\n",
              "       [1.8880860e-06],\n",
              "       [8.7798697e-13],\n",
              "       [1.0000000e+00],\n",
              "       [1.5102537e-05],\n",
              "       [3.6488424e-04],\n",
              "       [2.7155013e-05],\n",
              "       [6.8435990e-10],\n",
              "       [1.5808417e-06],\n",
              "       [9.3720033e-04],\n",
              "       [3.0428285e-02],\n",
              "       [9.9998474e-01],\n",
              "       [9.6191458e-12],\n",
              "       [9.9735004e-01],\n",
              "       [6.9037010e-03],\n",
              "       [5.5658424e-01],\n",
              "       [9.4938236e-01],\n",
              "       [1.9425595e-04],\n",
              "       [9.9792683e-01],\n",
              "       [9.9989831e-01],\n",
              "       [5.9905805e-04]], dtype=float32)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "1VZ-_pG2euD5"
      },
      "outputs": [],
      "source": [
        "y_pred =y_pred.flatten().astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzjT-uJieuGa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYCCNlvdeuJ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "dFZ7uCosdpXH",
        "outputId": "dc364e9c-21ab-49bc-e99e-56462bf4f83f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual y_value</th>\n",
              "      <th>Predicted y_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Actual y_value  Predicted y_value\n",
              "0               1                  0\n",
              "1               0                  0\n",
              "2               0                  0\n",
              "3               0                  0\n",
              "4               0                  0\n",
              "5               0                  0\n",
              "6               0                  0\n",
              "7               0                  0\n",
              "8               0                  0\n",
              "9               0                  0"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Comparing the actual and predicted y values\n",
        "\n",
        "pd.DataFrame({'Actual y_value':y_test.flatten(),'Predicted y_value':y_pred.flatten().astype('int')}).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "mZgBV-gbdpZa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXYCQBAXdpcQ",
        "outputId": "0c44b9f1-784f-446e-c9c3-002b138a893c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6754385964912281"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4mmqnx5ehF1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
